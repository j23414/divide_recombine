Exploring the Effect of Divide Recombine
========================================================
Team: Daniel Bero (dbero), Jennifer Chang (jenchang), Guillermo Basulto-Elias (basulto) 

Exercise 1
--------
Read Andee Kaplan's blog on comparing dplyr and datadr

Run the head to head comparison done by Andee. Do you get similar results?  Using proc.time() might help to do simple timing.

http://andeekaplan.com/2014/03/09/datadr/

Exercise 2
--------
Download the vehicle data from [http://www.fueleconomy.gov/feg/ws/index.shtml]

Your goal here is to compare fitting a glm of city mpg on highway mpg, cylinders, disp, fuelType and year using the full data, against drGLM() and drBLB().  Examine the time taken to compute, and the values of the model estimates.

It will be best to do some cleaning of the data before trying to fit the model, or making the ddf.
* Remove cars listed as year = 2015
* Remove missings on cylinders, displ and make into numeric variables
* Change fuelType into categories "Regular", "Premium", "Diesel", "Electricity", "E85"

Exercise 3
--------
Modify the MapReduce examples (at http://hafen.github.io/datadr/#mapreduce-examples) to:

Find the make of vehicle that has the lowest mpg

Exercise 4
---------
Write a paragraph on:
* How data cleaning prior to constructing the distributed data objects might be important.
* And how the data setup might affect the types of operations that can be done efficiently

Daniel Bero
```{r}
library(plyr)
gastype = cars.c$fuelType
cars.c$gastype = mapvalues(gastype, from=c("CNG", "Gasoline or natural gas", "Gasoline or propane",
                          "Regular", "Midgrade", "Premium", "Diesel", "Electricity",
                          "Premium Gas or Electricity", "Regular Gas and Electricity",
                          "Gasoline or E85", "Premium or E85"), to = c("Regular", 
                          "Regular", "Regular", "Regular", "Regular", "Premium", "Diesel",
                          "Electricity", "Electricity", "Electricity", "E85", "E85"))

time.glm = system.time(glm(UCity ~ UHighway + cylinders + displ + gastype + year, data = cars.c))
time.drGLM = system.time(drGLM(UCity ~ UHighway + cylinders + displ + gastype + year, data = cars.c))
time.drBLB = system.time({cars.d = ddf(cars.c, update=T)
cars.e <- divide(cars.d, by=rrDiv(17000), update=TRUE,postTrans=function(x) 
      x[,c("UCity", "UHighway", "cylinders", "displ", "gastype", "year")])

recombine(cars.e,
   apply=drBLB(
      statistic = function(x, weights)
         coef(glm(UCity ~ UHighway + cylinders + displ + gastype + year, 
            data=x, weights = weights)),
      metric = function(x)
         quantile(x, c(0.05, 0.95)),
      R = 100,
      n = nrow(cars.e)
   ),
   combine=combMean()
)

recombine(
    data = cars.e,
    apply = drGLM(UCity ~ UHighway+cylinders+displ+gastype+year),
    combine = combMeanCoef()
)})

time.glm
time.drGLM
time.drBLB
```

Jennifer Chang
```{r}
# Exercise 1 Andee Kaplan example
#library(devtools)
#install_github('datadr','hafen')
#library(datadr)
#data(adult)

# turn adult into a ddf
#(adultDdf<-ddf(adult, update=TRUE))
#names(adultDdf)
#library(ggplot2)
#edTable<-summary(adultDdf)$education$freqTable
#edTable$var

# Exercise 2 Cars
cars<-read.csv("vehicles.csv", header=TRUE)
cars.a <- subset(cars, year<2015)
cars.b <- subset(cars.a, cylinders!='' & cylinders!='-') # remove records wihtout cylinders data
cars.c <- subset(cars.b, displ!='' & displ!='-')         # remove records without displ data
#head(cars.c$cylinders)
cars.c$cylinders=as.numeric(as.character(cars.c$cylinders)) # convert cylinders to numeric
#head(cars.c$cylinders)
#head(cars.c$displ)
cars.c$displ=as.numeric(as.character(cars.c$displ))     # convert displ to numeric
#head(cars.c$displ)

summary(cars.c$fuelType)
summary(cars.c$fuelType1)
summary(cars.c$fuelType2)
summary(subset(cars.c[,c(31,32,68)], fuelType=='Gasoline or E85'))

library(plyr)
gastype = cars.c$fuelType
cars.c$gastype = mapvalues(gastype, from=c("CNG", "Gasoline or natural gas", "Gasoline or propane",
                          "Regular", "Midgrade", "Premium", "Diesel", "Electricity",
                          "Premium Gas or Electricity", "Regular Gas and Electricity",
                          "Gasoline or E85", "Premium or E85"), to = c("Regular", 
                          "Regular", "Regular", "Regular", "Regular", "Premium", "Diesel",
                          "Electricity", "Electricity", "Electricity", "E85", "E85"))
library(ggplot2)
```

Guillermo Basulto-Elias
We got the same conclusion: dplyr is faster..
```{r}
# Exercise 1 Andee Kaplan example
library(devtools)
#install_github('datadr','hafen')
library(datadr)
data(adult)

## turn adult into a ddf
(adultDdf<-ddf(adult, update=TRUE))
names(adultDdf)
library(ggplot2)
edTable<-summary(adultDdf)$education$freqTable
edTable$var

## Names
names(adultDdf)

## Plot
library(ggplot2)
edTable <- summary(adultDdf)$education$freqTable
edTable$var <- with(edTable, reorder(var, Freq, mean))
qplot(var, Freq, data = edTable, geom = "point") + coord_flip()


datadr_test <- function() {
    # make a preTransFn to group some education levels
    edGroups <- function(v) {
        v$edGroup <- as.character(v$education)
        v$edGroup[v$edGroup %in% c("1st-4th", "5th-6th")] <- "Some-elementary"
        v$edGroup[v$edGroup %in% c("7th-8th", "9th")] <- "Some-middle"
        v$edGroup[v$edGroup %in% c("10th", "11th", "12th")] <- "Some-HS"
        v
    }
    
    # divide by edGroup and filter out 'Preschool'
    byEdGroup <- divide(adultDdf, by = "edGroup", preTransFn = edGroups, filterFn = function(x) x$edGroup[1] != 
        "Preschool", update = TRUE)
    
    print(byEdGroup)
    
    # tabulate number of people in each education group
    edGroupTable <- recombine(byEdGroup, apply = nrow, combine = combRbind())
    print(edGroupTable)
    
    # order for plotting
    edGroupTable$edGroup <- with(edGroupTable, reorder(edGroup, val, mean))
    print(qplot(edGroup, val, data = edGroupTable, geom = "point") + coord_flip())
}
datadr_test()


### The same with plyr
library(dplyr)
dplyr_test <- function() {
    byEdGroup_dplyr <- adult %.% mutate(edGroup = ifelse(as.character(education) %in% 
        c("1st-4th", "5th-6th"), "Some-elementary", ifelse(as.character(education) %in% 
        c("7th-8th", "9th"), "Some-middle", ifelse(as.character(education) %in% 
        c("10th", "11th", "12th"), "Some-HS", as.character(education))))) %.% 
        filter(edGroup != "Preschool") %.% group_by(edGroup)
    print(byEdGroup_dplyr)
    
    edGroupTable_dplyr <- byEdGroup_dplyr %.% summarise(count = n())
    print(edGroupTable_dplyr)
    
    # order for plotting
    edGroupTable_dplyr$edGroup <- with(edGroupTable_dplyr, reorder(edGroup, 
        count, mean))
    print(qplot(edGroup, count, data = edGroupTable_dplyr, geom = "point") + 
        coord_flip())
}
dplyr_test()

library(profr)
system.time({
datadr_prof <- profr(datadr_test())
})

system.time({
dplyr_prof <- profr(dplyr_test())
})
```

For problem 3.
```{r}
# map expression to emit max petal length for each k/v pair
maxMap <- expression({
   for(curMapVal in map.values)
      collect("max", max(curMapVal$Petal.Length))
})

# reduce expression to compute global max petal length
maxReduce <- expression(
   pre={
      globalMax <- NULL
   },
   reduce={
      globalMax <- max(c(globalMax, unlist(reduce.values)))
   },
   post={
      collect(reduce.key, globalMax)
   }
)

# execute the job
maxRes <- mrExec(irisDdf,
   map = maxMap,
   reduce = maxReduce
)

# look at the result
maxRes[["max"]]

# another map expression to emit max petal length
maxMap2 <- expression(
   collect(
      "max",
      max(sapply(map.values, function(x) max(x$Petal.Length))))
)

```
